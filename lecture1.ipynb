{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2083a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "oai = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f598f6",
   "metadata": {},
   "source": [
    "#### Tool Calling + Parsing Structured Outputs Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81cba14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s the current temperature in Tokyo, Japan:\n",
      "\n",
      "- **Temperature:** 28°C (82°F)  \n",
      "- **Conditions:** Partly Cloudy 🌤️  \n",
      "- **Humidity:** 65%  \n",
      "- **Wind:** 10 km/h (6 mph)  \n",
      "\n",
      "Would you like additional details or a forecast for the day?\n"
     ]
    }
   ],
   "source": [
    "# Attempt 1: just tokens, no actual access to the tool\n",
    "# Result: hallucinates tool usage\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a weather tool.\n",
    "\n",
    "Args:\n",
    "    - city: str\n",
    "    - country: str\n",
    "    - scale: str (e.g., \"celsius\", \"fahrenheit\")\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"What's the temperature in Tokyo?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67392998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n",
      "```\n",
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n",
      "tool: weather\n",
      "args: {'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n",
      "  city: Tokyo\n",
      "  country: Japan\n",
      "  scale: celsius\n",
      "Calling tool weather with args {'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n",
      "The weather in Tokyo, Japan is 20 degrees (celsius).\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2: specifying output format in system prompt with a dummy tool call\n",
    "# Result: tool used correctly, but doesn't think or say any words -> no cot\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a weather tool.\n",
    "\n",
    "Args:\n",
    "    - city: str\n",
    "    - country: str\n",
    "    - scale: str (e.g., \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Call a tool by returning a JSON object with the following fields:\n",
    "    - tool: str\n",
    "    - args: dict\n",
    "\n",
    "Example:\n",
    "{\"tool\": \"weather\", \"args\": {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}}\n",
    "\"\"\"\n",
    "\n",
    "def dummy_weather_tool(city: str, country: str, scale: str):\n",
    "    return f\"The weather in {city}, {country} is 20 degrees ({scale}).\"\n",
    "\n",
    "tools = {\n",
    "    \"weather\": dummy_weather_tool,\n",
    "}\n",
    "\n",
    "def call_tool(tool: str, args: dict):\n",
    "    print(f\"Calling tool {tool} with args {args}\")\n",
    "    return tools[tool](**args)\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "\n",
    "response_str = response.choices[0].message.content\n",
    "print(response_str)\n",
    "\n",
    "def clean_response(response):\n",
    "    # Remove triple backticks and optional 'json' specifier (deepseek quirk)\n",
    "    cleaned = re.sub(r\"```json\\s*|\\s*```\", \"\", response.strip())\n",
    "    return cleaned\n",
    "\n",
    "response_str = clean_response(response_str)\n",
    "print(response_str)\n",
    "\n",
    "response_json = json.loads(response_str) # type: ignore\n",
    "for k, v in response_json.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "    if isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            print(f\"  {k2}: {v2}\")\n",
    "\n",
    "tool_response = call_tool(response_json[\"tool\"], response_json[\"args\"])\n",
    "print(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adc2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m response_str \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_str)\n\u001b[0;32m---> 41\u001b[0m response_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m response_json\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Attempt 3: using a system prompt that encourages step-by-step reasoning\n",
    "# Result: error, since the output is not a valid JSON object\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a 'weather' tool. **Always think step-by-step before calling a tool.**\n",
    "\n",
    "Args:\n",
    "    - city: str\n",
    "    - country: str\n",
    "    - scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Call a tool by returning a JSON object with the following fields:\n",
    "- tool: str\n",
    "- args: dict\n",
    "\n",
    "Example:\n",
    "I should call the weather tool with the given args:\n",
    "{\"tool\": \"weather\", \"args\": {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}}\n",
    "\"\"\"\n",
    "\n",
    "def dummy_weather_tool(city: str, country: str, scale: str):\n",
    "    return f\"The weather in {city}, {country} is 20 degrees ({scale}).\"\n",
    "\n",
    "tools = {\n",
    "    \"weather\": dummy_weather_tool,\n",
    "}\n",
    "\n",
    "def call_tool(tool: str, args: dict):\n",
    "    print(f\"Calling tool {tool} with args {args}\")\n",
    "    return tools[tool](**args)\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo in Celsius?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "response_str = response.choices[0].message.content\n",
    "print(response_str)\n",
    "\n",
    "response_json = json.loads(response_str) # type: ignore\n",
    "for k, v in response_json.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "    if isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            print(f\"  {k2}: {v2}\")\n",
    "\n",
    "tool_response = call_tool(response_json[\"tool\"], response_json[\"args\"])\n",
    "print(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9HMhr4PiS6Sug59BPeivow', function=Function(arguments='{\"city\":\"Tokyo\",\"country\":\"Japan\",\"scale\":\"celsius\"}', name='get_weather'), type='function', index=0)], reasoning=None), native_finish_reason='tool_calls')\n",
      "{'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n"
     ]
    }
   ],
   "source": [
    "# Attempt 4: old-school openai solution - input in-depth schema of the tool with instructions on how to fill out the function call\n",
    "# Ensures structured outputs\n",
    "# For self-hosting: backends for structured parsing (Outlines, XGrammar) which essentially are applying regex masks\n",
    "# Result: tool used correctly, but no CoT\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the weather for a given city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city to get the weather for\"\n",
    "                },\n",
    "                \"country\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The country to get the weather for\"\n",
    "                },\n",
    "                \"scale\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The scale to get the weather for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\", \"country\", \"scale\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    tools=tools, # type: ignore\n",
    ")\n",
    "print(response.choices[0])\n",
    "\n",
    "tool_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments) # type: ignore\n",
    "print(tool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df4874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think='I need to find the weather for Tokyo. Since the country is not specified, I will use Japan as the default country for Tokyo and default to Celsius for the temperature scale.' args=WeatherArgs(city='Tokyo', country='Japan', scale='celsius')\n"
     ]
    }
   ],
   "source": [
    "# Attempt 5: use pydantic - allows you to create complex nested structures to define our outputs\n",
    "# Result: tool used correctly, with CoT thinking before tool call\n",
    "# Cons: not all providers suppport pydantic structured outputs natively\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class WeatherArgs(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "    scale: Literal[\"celsius\", \"fahrenheit\"]  # Use \"Literal\" for guaranteed outputs (e.g., model may output \"C\" or \"Celsius\" in the wrong case)\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    think: str  # forces thinking before tool call\n",
    "    args: WeatherArgs\n",
    "\n",
    "\n",
    "response = oai.beta.chat.completions.parse(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "response_obj = response.choices[0].message.parsed\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1a3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'celsius'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_obj.args.scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maven-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
